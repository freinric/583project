---
title: "EDA"
author: "Ricky Heinrich"
date: "2023-03-10"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

### Workflow for current and next step in the project

To determine which model would fit this data, we need to consider several factors such as the nature of the problem, the available data, and the type of output that we are trying to predict.

First, we need to define the problem and the goal of the model. In this case, we are trying to **predict the number of bikes rented per hour (cnt)**, given the various features such as weather, time of day, and other factors. This is a regression problem, as we are trying to predict a discrete variable.

Second, we need to examine the available data and determine if there are any missing values, outliers, or other anomalies. If the data is incomplete, we may need to consider techniques such as imputation or data cleaning to address these issues.

Third, we need to select appropriate features for the model. Some features, such as season or weather, may have a strong correlation with the number of bikes rented, while others may not be as important. Feature selection can be done using techniques such as correlation analysis or principal component analysis.

Finally, we can select a model that is appropriate for the problem at hand. Some popular models for regression problems include linear regression, decision trees, random forests, and neural networks. We can use techniques such as cross-validation to evaluate different models and select the one that performs best on the data.

### Statistically Descriptive Analysis of the Dataset

```{r, echo=FALSE, results='hide', include=FALSE}
library(tidyverse)
library(ggplot2)
df <- read_csv("Bike-Sharing-Dataset/hour.csv")
df$rawtemp = df$temp*47-8 # converting temp to raw form
df$rawatemp = df$atemp*66-16 # converting atemp to raw
df$rawhum = df$hum*100 # converting hum to raw form
df$rawwindspeed = df$windspeed*67 # converting windspeed to raw form 
plotlist = list()
for (i in colnames(df)[-c(1,2)]){
  plotlist[[i]] <- ggplot(df, aes_string(x=i))+geom_bar()
}
```
the number of variables, variables types, summary statistics, graphs of data

#### Date related variables
The dataset contains 17 variables, where the first column is an index.
Most of the data is numerical in nature, apart from the *dteday* column, which records the date in a date format. This date is separated further in year, month, and hour columns, which are factored into discrete numeric variables, similarly to the *weekday* variable, where Sunday is 0. The *year*, *holiday*, and *workinday* variables are boolean variables. For the *year*, a '0' represents 2011, and a '1' 2012. 

We were expecting that the counts of observations for each year, weekday and hour are uniform across categories, as each should have the same number of hours. We suppose that there is a dip in 'observations' for the hours of 2,3,4,5 due to some days containing no rides during that hour. The count of hours with rides is slightly lower in 2011 than 2012, and we see a small concave curve with Sunday and Saturday on both ends and where there minimum count is on Tuesday.

```{r, echo=FALSE, fig.width=7, fig.height=2,fig.cap = "Count of rows per Year, Hour, and Weekday"}
cowplot::plot_grid(plotlist = plotlist[c(2,4,6)], ncol = 3)
```

The distributions of counts for season, month, holiday, and workingday are not interesting on their own, as each category is not meant to have the same number of hours (February has 72 less hours total than March since its got 3 days less). We cannot infer if the dips are due to hours containing no rides or just how the categories are set. 

```{r, echo=FALSE, fig.width=6, fig.height=4,fig.cap = "Count of rows per Season, Month, Holiday, and Workingday"}
cowplot::plot_grid(plotlist = plotlist[c(1,3,5,7)], ncol = 2)
```

The *weathersit* variable is categorical, where the conditions were classified into four. The data can be taken as ordinal, with '1' being the most 'pleasant' weather, and 4 the least. From the original data source description: 

- 1: Clear, Few clouds, Partly cloudy, Partly cloudy; 

- 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist; 

- 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds; 

- 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog.

We see that a majority of cases are classified as '1', and decreasing counts as the weather gets less pleasant. We know the data doesn't contain an exhaustive list of all hours, but assuming the effect of missing hours is not great, this tells us that the weather is pleasant most of the time in DC. 

```{r, echo=FALSE, fig.width=4, fig.height=3, fig.cap = "Count of rows per weather category"}
plotlist[8][[1]]
```


The rest of the weather related variables, *temp*, *atemp*, *hum* and *windspeed* have been scaled. We've transformed the data in new columns to get back original values to help make charts interpretable. In the 'temp' plot, we see what looks like a symmetric bimodal distribution. We know that the minimum is -8, and the maximum is +39 Celsius. 'atemp', which is the feeling temperature, shows more of a flattened peak, although there is one value that is recorded about doubly more often than any other. Similarly there's a few troughs, but generally it seems symmetric.  We would have expected a more continuous distribution, so there might be something going on in regards to rounding or collection of data. Similarly, we would have expected more continuous data for the humidity records, as well as the windspeed. 

```{r, echo=FALSE, fig.width=6, fig.height=4, fig.cap = "Count of rows per temp, atemp, hum, and windspeed"}
cowplot::plot_grid(plotlist = plotlist[16:19], nrow = 2)
```
```{r}
summary(df[18:21])
```


Finally, *casual*, *registered*, and *cnt* are counts of bikes rented during each 'hour', corresponding to the count of casual users, registered users, and the sum of both. For the count of casual users during a given hour, we see what looks like a steep exponential decline. Intuitively, less users during a given hour happen a lot more often then a lot of users. The distribution of registered users sees less of an extreme drop, with a less steep decline from 50 counts on of individual hours observing a minimum of about 75 rides on. We see that there is a lot more counts of casual users however (peaking >1500 vs >300), so on the same y-scale the distributions might look different. More investigation is needed in that regard. 

```{r, echo=FALSE, fig.width=7, fig.height=2,fig.cap = "Count of rows per temp, atemp, hum, and windspeed"}
cowplot::plot_grid(plotlist = plotlist[13:15], ncol = 3)
```
```{r}
summary(df[15:17])
```
```{r}
# trying to build a box plot with all of these on one plot ..
#ggplot(df, aes())
```


## To see if Bike Rental Count is different for both years

```{r echo=FALSE, fig.width=8, fig.height=3}
library(tidyverse)

# aggregate by day, add year
day_sum <- aggregate(cnt~dteday, df, sum)
day_sum$yr <- format(day_sum$dteday,"%Y")

bikeperyrbox <- ggplot(day_sum, aes(x = factor(yr), y = cnt)) +
  geom_boxplot(fill = "red") +
  labs(title = "Bike Rental Count by Year", x = "", y = "Bike Rentals") +
  theme(axis.title.x = element_text(size = 11), 
        axis.title.y = element_text(size = 11), 
        plot.title = element_text(size = 15, hjust = 0.5),
        legend.position = "top", legend.justification = "right",
        legend.text = element_text(size = 9),
        axis.text.x = element_text(size = 7),
        axis.text.y = element_text(size = 7)) +
  scale_x_discrete(labels = c("2011", "2012"), name = "Years", 
                   breaks = c(0, 1))

# Find the smallest value of cnt for 2012
myday_2012 <- subset(day_sum, yr == 2012)

min_cnt <- min(myday_2012$cnt)

# Create a new column indicating the smallest value
myday_2012$min_cnt <- ifelse(myday_2012$cnt == min_cnt, "Smallest Value", "Other Values")

# Plot cnt per day for the year 2012
scattercnt <- ggplot(myday_2012, aes(x = dteday, y = cnt, color = min_cnt)) +
geom_point(size = 2.5) +
labs(title = "Bike Rental Counts per Day - 2012",
   x = "",
   y = "Rental Count") +
theme(axis.title.x = element_text(size = 15), 
    axis.title.y = element_text(size = 11), 
    plot.title = element_text(size = 15, hjust = 0.5),
    legend.position = "top", legend.justification = "right",
    legend.text = element_text(size = 14),
    axis.text.x = element_text(size = 7),
    axis.text.y = element_text(size = 7)) +
scale_color_manual(values = c("black", "red"), guide = "none")


cowplot::plot_grid(plotlist = list(bikeperyrbox, scattercnt), ncol = 2)
```


* The number of bikes rented out has increased from 2011 in 2012.
* Also, we notice the outlier in 2012 which can be seen as a dot towards the bottom of the plot, plotted in red in the scatterplot.

Let us explore this further:

```{r}
myday_2012 <- subset(day_sum, yr == 2012)
mydata = myday_2012[myday_2012$cnt == min(myday_2012$cnt), c("cnt","dteday")]
cbind(yearly_mean = mean(myday_2012$cnt), mydata)
```

We see that the number of bikes rented out on October 29, 2012 was underwhelmingly lower than the yearly average for 2012 making it an outlier. We investigated further to see why that is and found the following:

\![](1.png)

It was because of this natural calamity that the number of bike rental counts was super low. We have also successfully used this data set to find a natural calamity. 

## Check if 'weathersit' and 'holiday' variables are important using ANOVA

```{r}
lm <- lm(cnt ~ weathersit + holiday, data = df)
anova (lm)
```

F values greater than 1, and pvalues less than 0.05 show that both these variables are significant in predicting count of bike rentals.

# To do
## fix the plots in report so flows smoothly after text, idk why they don't go where they are assigned

## average bike rental plots per month, per hour, per weekday

## what questions we will answer: how will try to answer more explicitely
- what is most influencal variable: do that random forest gni index thing, which variable has most different MSE when removed ?
- can we predict number of bikes given set of conditions : regression, could try non-parametric even tho you said linear regression is perfect fit lol
- maybe we could try to cluster registered vs not registered. actually probably can't since its aggregated, this would be something from og og data

## I think the normality plots about the weather data are not that interesting and I don't see the purpose of including them

## I like bike rental counts vs temperature, still think the colour scale is not the most straighforward so maybe we can come up with something more 



