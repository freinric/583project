---
title: "EDA"
author: "Ricky Heinrich & Vimaljeet Singh"
date: "2023-03-10"
output: 
  pdf_document: 
    extra_dependencies: ["float"]
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,fig.pos = "H", out.extra = "", fig.align = 'center')
```

## Workflow for current and next step in the project

To determine which model would fit this data, we need to consider several factors such as the nature of the problem, the available data, and the type of output that we are trying to predict.

First, we need to define the problem and the goal of the model. In this case, we are trying to **predict the number of bikes rented per hour (cnt)**, given the various features such as weather, time of day, and other factors. We also want to know which predictors influence the number of bikes rented the most. This is a regression problem.

Second, we need to examine the available data and determine if there are any missing values, outliers, or other anomalies. If the data is incomplete, we may need to consider techniques such as imputation or data cleaning to address these issues.

Third, we need to select appropriate features for the model. Some features, such as season or weather, may have a strong correlation with the number of bikes rented, while others may not be as important. Feature selection can be done using techniques such as correlation analysis or principal component analysis.

Finally, we can select a model that is appropriate for the problem at hand. Some popular models for regression problems include linear regression, decision trees, random forests, and neural networks. We can use techniques such as cross-validation to evaluate different models and select the one that performs best on the data. From a multi linear regression, we may observe the p-value or use step-wise regression to determine which predictors are the most useful. In a random forest model, we may determine the importance of a predictor using the Gini Index.

## Statistically Descriptive Analysis of the Dataset

```{r, echo=FALSE, results='hide', include=FALSE}
library(tidyverse)
library(ggplot2)
df <- read_csv("Bike-Sharing-Dataset/hour.csv")
df$rawtemp = df$temp*47-8 # converting temp to raw form
df$rawatemp = df$atemp*66-16 # converting atemp to raw
df$rawhum = df$hum*100 # converting hum to raw form
df$rawwindspeed = df$windspeed*67 # converting windspeed to raw form 
plotlist = list()
for (i in colnames(df)[-c(1,2)]){
  plotlist[[i]] <- ggplot(df, aes_string(x=i))+geom_bar()
}
```

### Date related variables

The dataset contains 17 variables, where the first column is an index.
Most of the data is numerical in nature, apart from the *dteday* column, which records the date in a date format. This date is separated further in year, month, and hour columns, which are factored into discrete numeric variables, similarly to the *weekday* variable, where Sunday is 0. The *year*, *holiday*, and *workinday* variables are boolean variables. For the *year*, a '0' represents 2011, and a '1' 2012. 

We were expecting that the counts of observations for each year, weekday and hour are uniform across categories, as each should have the same number of hours. We suppose that there is a dip in 'observations' for the hours of 2,3,4,5 due to some days containing no rides during that hour. The count of hours with rides is slightly lower in 2011 than 2012, and we see a small concave curve with Sunday and Saturday on both ends and where there minimum count is on Tuesday.

```{r, echo=FALSE, fig.width=7, fig.height=2,fig.cap = "Count of rows per Year, Hour, and Weekday"}
cowplot::plot_grid(plotlist = plotlist[c(2,4,6)], ncol = 3)
```

The distributions of counts for season, month, holiday, and workingday are not interesting on their own, as each category is not meant to have the same number of hours (February has 72 less hours total than March since its got 3 days less). We cannot infer if the dips are due to hours containing no rides or just how the categories are set. 

```{r, echo=FALSE, fig.width=6, fig.height=4,fig.cap = "Count of rows per Season, Month, Holiday, and Workingday"}
cowplot::plot_grid(plotlist = plotlist[c(1,3,5,7)], ncol = 2)
```

### Weather related variables

The *weathersit* variable is categorical, where the conditions were classified into four. The data can be taken as ordinal, with '1' being the most 'pleasant' weather, and 4 the least. From the original data source description: 

- 1: Clear, Few clouds, Partly cloudy, Partly cloudy; 

- 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist; 

- 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds; 

- 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog.

We see that a majority of cases are classified as '1', and decreasing counts as the weather gets less pleasant. We know the data doesn't contain an exhaustive list of all hours, but assuming the effect of missing hours is not great, this tells us that the weather is pleasant most of the time in DC. 

```{r, echo=FALSE, fig.width=4, fig.height=3, fig.cap = "Count of rows per weather category"}
plotlist[8][[1]]
```


The rest of the weather related variables, *temp*, *atemp*, *hum* and *windspeed* have been scaled. We've transformed the data in new columns to get back original values to help make charts interpretable. In the 'temp' plot, we see what looks like a symmetric bimodal distribution. We know that the minimum is -8, and the maximum is +39 Celsius. 'atemp', which is the feeling temperature, shows more of a flattened peak, although there is one value that is recorded about doubly more often than any other. Similarly there's a few troughs, but generally it seems symmetric.  We would have expected a more continuous distribution, so there might be something going on in regards to rounding or collection of data. Similarly, we would have expected more continuous data for the humidity records, as well as the windspeed. 

```{r, echo=FALSE, fig.width=6, fig.height=4, fig.cap = "Count of rows per temp, atemp, hum, and windspeed"}
cowplot::plot_grid(plotlist = plotlist[16:19], nrow = 2)
```
```{r}
summary(df[18:21])
```

### Response data

Finally, *casual*, *registered*, and *cnt* are counts of bikes rented during each 'hour', corresponding to the count of casual users, registered users, and the sum of both. For the count of casual users during a given hour, we see what looks like a steep exponential decline. Intuitively, less users during a given hour happen a lot more often then a lot of users. The distribution of registered users sees less of an extreme drop, with a less steep decline from 50 counts on of individual hours observing a minimum of about 75 rides on. We see that there is a lot more counts of casual users however (peaking >1500 vs >300), so on the same y-scale the distributions might look different. More investigation is needed in that regard. 

```{r, echo=FALSE, fig.width=7, fig.height=2,fig.cap = "Count of rows per temp, atemp, hum, and windspeed"}
cowplot::plot_grid(plotlist = plotlist[13:15], ncol = 3)
```
```{r}
summary(df[15:17])
```

## ANOVA, correlation
### Check if 'weathersit' and 'holiday' variables are important using ANOVA

```{r, echo=FALSE}
lm <- lm(cnt ~ weathersit + holiday, data = df)
anova (lm)
```

F values greater than 1, and pvalues less than 0.05 show that both these variables are significant in predicting count of bike rentals.

### Weather correlations
```{r, echo=FALSE}
cor.hum <- cor.test(x = df$cnt, y = df$hum)
cor.temp <- cor.test(x = df$cnt, y = df$temp)
cor.ws <- cor.test(x = df$cnt, y = df$windspeed)
cbind(corr_hum=cor.hum[4], corr_temp=cor.temp[4], corr_ws=cor.ws[4])
```
It seems like the number of bike rentals is negatively correlated with the humidity, and positively correlated with the temperature. The correlation value with the wind is very close to 0, so it doesn't seem like there is a relation between windspeed and number of bike rentals.

## Exploratory Charts

### Bike Rental Count per Year

```{r echo=FALSE, fig.width=8, fig.height=3, fig.cap = "Left: Distribution of bike rental count per year, Right: 2012 daily bike rental count"}
library(tidyverse)

# aggregate by day, add year
day_sum <- aggregate(cnt~dteday, df, sum)
day_sum$yr <- format(day_sum$dteday,"%Y")

bikeperyrbox <- ggplot(day_sum, aes(x = factor(yr), y = cnt)) +
  geom_boxplot(fill = "red") +
  labs(title = "", x = "", y = "Bike Rentals") +
  theme(axis.title.x = element_text(size = 11), 
        axis.title.y = element_text(size = 11), 
        plot.title = element_text(size = 15, hjust = 0.5),
        legend.position = "top", legend.justification = "right",
        legend.text = element_text(size = 9),
        axis.text.x = element_text(size = 7),
        axis.text.y = element_text(size = 7)) +
  scale_x_discrete(labels = c("2011", "2012"), name = "Years", 
                   breaks = c(0, 1))

# Find the smallest value of cnt for 2012
myday_2012 <- subset(day_sum, yr == 2012)

min_cnt <- min(myday_2012$cnt)

# Create a new column indicating the smallest value
myday_2012$min_cnt <- ifelse(myday_2012$cnt == min_cnt, "Smallest Value", "Other Values")

# Plot cnt per day for the year 2012
scattercnt <- ggplot(myday_2012, aes(x = dteday, y = cnt, color = min_cnt)) +
geom_point(size = 2.5) +
labs(title = "",
   x = "",
   y = "Rental Count") +
theme(axis.title.x = element_text(size = 15), 
    axis.title.y = element_text(size = 11), 
    plot.title = element_text(size = 15, hjust = 0.5),
    legend.position = "top", legend.justification = "right",
    legend.text = element_text(size = 14),
    axis.text.x = element_text(size = 7),
    axis.text.y = element_text(size = 7)) +
scale_color_manual(values = c("black", "red"), guide = "none")


cowplot::plot_grid(plotlist = list(bikeperyrbox, scattercnt), ncol = 2)
```


* The number of bikes rented out has increased from 2011 in 2012.
* Also, we notice the outlier in 2012 which can be seen as a dot towards the bottom of the plot, plotted in red in the scatterplot.

Let us explore this further:

```{r}
myday_2012 <- subset(day_sum, yr == 2012)
mydata = myday_2012[myday_2012$cnt == min(myday_2012$cnt), c("cnt","dteday")]
cbind(yearly_mean = mean(myday_2012$cnt), mydata)
```

We see that the number of bikes rented out on October 29, 2012 was underwhelmingly lower than the yearly average for 2012 making it an outlier. We investigated further to see why that is and found the following:

\![](1.png)

It was because of this natural calamity that the number of bike rental counts was super low. We have also successfully used this data set to find a natural calamity. 


### Bike Rental Counts per Month

[write about what we see: ]
This next figure plots the count of bikes used for every month, split by year. Interestingly, 2011 sees a flat peak in June and a gradual decline into the winter months. The next year has a big jump from February to March, then climbs gradually to peak in September before seeing a steeper decline into the winter months.

```{r, echo = FALSE, fig.width=4, fig.height=3, fig.cap = "Count of bike rentals per month"}
ggplot(df, aes(x = mnth, y = cnt, color = factor(yr))) +
  geom_point(size= 3,stat = 'summary', fun = 'sum' ) +
  geom_line(stat = 'summary', fun = 'sum') +
  labs(title = "",
       x = "",
       y = "Rental Count",
       color = "Year") +
  theme(axis.title.x = element_text(size = 11), 
        axis.title.y = element_text(size = 11), 
        plot.title = element_text(size = 15, hjust = 0.5),
        legend.position = "top", legend.justification = "right",
        legend.text = element_text(size = 7),
        axis.text.x = element_text(size = 7),
        axis.text.y = element_text(size = 7)) +
  scale_x_continuous(breaks = seq(1, 12, by = 1), 
                     labels = c("Jan", "Feb", "Mar", "Apr", "May", "Jun", 
                                "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"))+
       scale_color_hue(labels = c("2011", "2012"))
```


##  try to average daily: Daily averages per month instead of count

### Bike Rental Counts per Hour
Next, we can see that both years follow a similar trend in average rental count per hour of day. There is a similar low number of bikes rented out in the hours of 2,3,4 and 5 in both years. The change is greatest in the daytime hours: 7am to 9pm. In an seasons, we observe peaks at 8am and 5pm, suggesting that people use the rental system as transportation to work. 

```{r, echo=FALSE, fig.width=7, fig.height=5, fig.cap = "Average bike rental counts per hour, per season"}
ggplot(df, aes(x = hr, y = cnt, color = factor(yr))) +
  geom_point(size= 2,stat = 'summary', fun = 'mean' ) +
  geom_line(stat = 'summary', fun = 'mean') +
  labs(title = "",
       x = "Hour",
       y = "Average Rental Count",
       color = "Year") +
  theme(axis.title.x = element_text(size = 11), 
        axis.title.y = element_text(size = 11), 
        plot.title = element_text(size = 15, hjust = 0.5),
        legend.position = "top", legend.justification = "right",
        legend.text = element_text(size = 7),
        axis.text.x = element_text(size = 7),
        axis.text.y = element_text(size = 7)) + 
  facet_wrap(vars(season), labeller = as_labeller(c(`1` = 'Winter', `2` = 'Spring',  `3`= 'Summer', `4`= 'Fall')))+
  scale_x_continuous(breaks = seq(0, 23, by = 2))+
       scale_color_hue(labels = c("2011", "2012"))
```
### Bike Rental Counts per Weekday
[per weekday] Interestingly, we don't observe a drop of rides during the weekends in every season. The trends are not similar for neither both years nor all seasons.

```{r, echo=FALSE, fig.width=7, fig.height=5, fig.cap = "Average bike rental counts per weekday, per season"}
ggplot(df, aes(x = weekday, y = cnt, color = factor(yr))) +
  geom_point(size= 3,stat = 'summary', fun = 'mean' ) +
  geom_line(stat = 'summary', fun = 'mean') +
  labs(title = "",
       x = "Hour",
       y = "Average Rental Count",
       color = "Year") +
  theme(axis.title.x = element_text(size = 11), 
        axis.title.y = element_text(size = 11), 
        plot.title = element_text(size = 15, hjust = 0.5),
        legend.position = "top", legend.justification = "right",
        legend.text = element_text(size = 7),
        axis.text.x = element_text(size = 7),
        axis.text.y = element_text(size = 7)) + 
  facet_wrap(vars(season), labeller = as_labeller(c(`1` = 'Winter', `2` = 'Spring',  `3`= 'Summer', `4`= 'Fall')))+
  scale_x_continuous(breaks = seq(0, 6, by = 1), labels = c("Sun", "Mon", "Tues", "Wed","Thurs","Fri","Sat" ))+
       scale_color_hue(labels = c("2011", "2012"))
```

# To do

## casual vs registered during seasons, hour, weekday could be interesting

## I like bike rental counts vs temperature, still think the colour scale is not the most straighforward so maybe we can come up with something more 

## talk about the variable summaries I printed earlier

## check correlation matrix of all variables ? months probably correlated with temp for example



